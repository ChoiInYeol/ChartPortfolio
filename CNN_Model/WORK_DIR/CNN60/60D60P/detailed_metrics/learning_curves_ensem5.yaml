model_0:
  train:
    accuracy: []
    loss: []
    mcc: []
  validate:
    accuracy:
    - 0.5828414368620178
    - 0.5849939151095694
    - 0.5788179582915945
    - 0.5851180965469281
    - 0.5946221158861174
    - 0.5912692170774313
    - 0.5951519566855147
    - 0.5913851197522995
    - 0.5971719747332169
    - 0.5941419476616635
    - 0.5903502744409765
    - 0.598480019206729
    - 0.5488074442632316
    loss:
    - 0.7215837518477092
    - 0.692737184434029
    - 0.677850968910315
    - 0.671809587388849
    - 0.6836263314272546
    - 0.670170967153887
    - 0.6827281429765221
    - 0.6692512425158028
    - 0.688461603470128
    - 0.6689462676694781
    - 0.6697496174645854
    - 0.6895425687742932
    - 0.700080821177812
    mcc:
    - 0.05692277366101996
    - 0.07703724913267282
    - 0.11103833842957857
    - 0.10994475216547893
    - 0.09827251019984751
    - 0.11665045413322882
    - 0.09968646622273557
    - 0.12202072551503536
    - 0.10711467783876213
    - 0.12364721988752292
    - 0.12464897058501023
    - 0.11190846881745833
    - 0.13292524842336376
model_1:
  train:
    accuracy: []
    loss: []
    mcc: []
  validate:
    accuracy:
    - 0.5733125812353569
    - 0.591749385301885
    - 0.591732827776904
    - 0.5905324072157694
    - 0.5968822180460465
    - 0.5955576160475532
    - 0.5987283820814465
    - 0.5795133743408035
    - 0.5901267478537309
    loss:
    - 0.695678434843314
    - 0.6808248293651373
    - 0.6757405412074639
    - 0.7037795537307089
    - 0.6720705531101012
    - 0.667629827971237
    - 0.6722600322877574
    - 0.6745700101993111
    - 0.6689790709343143
    mcc:
    - 0.08260751362806644
    - 0.10306935811348643
    - 0.0998305811824815
    - 0.07071321617477715
    - 0.10824314193060491
    - 0.12397561161420564
    - 0.10880448508437815
    - 0.1325109787183717
    - 0.13028173404302976
model_2:
  train:
    accuracy: []
    loss: []
    mcc: []
  validate:
    accuracy:
    - 0.551696732372445
    - 0.587345083656895
    - 0.5892409202672384
    - 0.556241772979775
    - 0.5787351706666888
    - 0.5927925093756985
    - 0.5956900762474026
    - 0.5980660810821998
    - 0.5395186727487975
    - 0.5875354951941784
    loss:
    - 0.7020837607941014
    - 0.7116024501168302
    - 0.6781453879275632
    - 0.6866315553570473
    - 0.6738573975145628
    - 0.6705730053009692
    - 0.6686334466918611
    - 0.6704730659693922
    - 0.7004453966087834
    - 0.6712574089238926
    mcc:
    - 0.08311755675143281
    - 0.07022400957057438
    - 0.09491275719100885
    - 0.11833570367790966
    - 0.12293960602378814
    - 0.11457320486799355
    - 0.12150670826670337
    - 0.12144528826721174
    - 0.12152472945361262
    - 0.12939038577475573
model_3:
  train:
    accuracy: []
    loss: []
    mcc: []
  validate:
    accuracy:
    - 0.5692725451399525
    - 0.5897210884916922
    - 0.5878583669313111
    - 0.5950691690606088
    - 0.5942992441489846
    - 0.5877838580688959
    - 0.564636438145226
    - 0.6018660330653773
    - 0.5953092531728357
    - 0.5808214188143156
    - 0.6009884842413756
    loss:
    - 0.6938097488288902
    - 0.7215181757625879
    - 0.6778405202690334
    - 0.6785095918582301
    - 0.6686399756222348
    - 0.6694235554185839
    - 0.6843132992045827
    - 0.6682737277167391
    - 0.6977112295824166
    - 0.6728929296625531
    - 0.6721774876665932
    mcc:
    - 0.07556321779903968
    - 0.06589841273026864
    - 0.0988925270119404
    - 0.09498472492592105
    - 0.12141233860386388
    - 0.12837735859016963
    - 0.1228179362908557
    - 0.1245251231897902
    - 0.09301083526529937
    - 0.13333707380895246
    - 0.12034974033883271
model_4:
  train:
    accuracy: []
    loss: []
    mcc: []
  validate:
    accuracy:
    - 0.5844226804977192
    - 0.5871795084070833
    - 0.5918984030267156
    - 0.576963515493704
    - 0.5968242667086124
    - 0.5982150988070303
    - 0.5447011780679024
    - 0.5894313318045219
    - 0.5964020498215926
    - 0.5967497578461971
    - 0.5973789437954814
    loss:
    - 0.7212931715682487
    - 0.6892203520645288
    - 0.6927823306468248
    - 0.6775011348289732
    - 0.6745718073787077
    - 0.6839924608636399
    - 0.6964048756403435
    - 0.6709364327157202
    - 0.6777430407986597
    - 0.7140642131178545
    - 0.6786265182372346
    mcc:
    - 0.06779413951673338
    - 0.08582150461611134
    - 0.08629957339678807
    - 0.11682800100074545
    - 0.11307089706571113
    - 0.11128607426414912
    - 0.12316053322470805
    - 0.1216647665035083
    - 0.10994744997910211
    - 0.10520456164121328
    - 0.11638774748456626
