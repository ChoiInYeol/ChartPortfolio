confusion_matrices:
  model_0:
    train:
      best: null
      final: null
    validate:
      best:
        FN: 21865
        FP: 33358
        TN: 24344
        TP: 46672
      final:
        FN: 11716
        FP: 42957
        TN: 14745
        TP: 56821
  model_1:
    train:
      best: null
      final: null
    validate:
      best:
        FN: 15462
        FP: 39280
        TN: 18252
        TP: 53245
      final:
        FN: 31286
        FP: 25162
        TN: 32370
        TP: 37421
  model_2:
    train:
      best: null
      final: null
    validate:
      best:
        FN: 19064
        FP: 35492
        TN: 22001
        TP: 49682
      final:
        FN: 11578
        FP: 42841
        TN: 14652
        TP: 57168
  model_3:
    train:
      best: null
      final: null
    validate:
      best:
        FN: 20111
        FP: 34773
        TN: 22877
        TP: 48478
      final:
        FN: 16650
        FP: 37951
        TN: 19699
        TP: 51939
  model_4:
    train:
      best: null
      final: null
    validate:
      best:
        FN: 14686
        FP: 39895
        TN: 17690
        TP: 53968
      final:
        FN: 8087
        FP: 46500
        TN: 11085
        TP: 60567
learning_curves:
  model_0:
    train:
      accuracy: []
      loss: []
      mcc: []
    validate:
      accuracy:
      - 0.5316740468476462
      - 0.5509945420987176
      - 0.5384389927043148
      - 0.551778768843226
      - 0.5600884037421082
      - 0.5401500328741514
      - 0.5591378258699768
      - 0.5538225112683085
      - 0.5578149383312605
      - 0.5661721021237494
      - 0.5651264664644048
      - 0.5625519847273822
      - 0.5659582221025198
      - 0.5666157051307441
      - 0.5669087999746513
      loss:
      - 0.7147084355140894
      - 0.7009758077040299
      - 0.6940130084871784
      - 0.6860374293650741
      - 0.6855469360905233
      - 0.6899341341495223
      - 0.681279318498437
      - 0.6994214576010946
      - 0.6907493720340641
      - 0.6796326864068747
      - 0.6823099419187885
      - 0.6793417746504238
      - 0.6810269103755332
      - 0.6797359651273827
      - 0.6804419975545396
      mcc:
      - 0.05130497632650164
      - 0.06573478694860138
      - 0.07955866266060231
      - 0.08700432364421957
      - 0.08480345713288633
      - 0.09593710339268018
      - 0.09747785159872124
      - 0.07094674023728957
      - 0.08037167574180892
      - 0.10236745302628716
      - 0.0984390582666241
      - 0.10637620179808696
      - 0.1005993069898612
      - 0.10468086533702778
      - 0.10353123883480579
  model_1:
    train:
      accuracy: []
      loss: []
      mcc: []
    validate:
      accuracy:
      - 0.5382964060234952
      - 0.5487289981701376
      - 0.5492359730352744
      - 0.5580921902106322
      - 0.5560088403742108
      - 0.5561989559486371
      - 0.5621400676494586
      - 0.5620687743090487
      - 0.5616647787133928
      - 0.5656096768827383
      - 0.5641125167341313
      - 0.5589714747423538
      - 0.5663622176981756
      - 0.5681762371374932
      - 0.5637005996562077
      - 0.5528481689493738
      loss:
      - 0.7137331189517848
      - 0.6980928030387911
      - 0.689470317734779
      - 0.6858704841679252
      - 0.683943439212613
      - 0.6833656322002423
      - 0.6831471378425584
      - 0.683085347545097
      - 0.6843077925271812
      - 0.6798816891960554
      - 0.67987909697783
      - 0.6807906368719334
      - 0.6790954305865784
      - 0.6801349323038312
      - 0.6794778609111696
      - 0.6838706358145271
      mcc:
      - 0.04895945372420542
      - 0.0622506381076704
      - 0.0808303180302967
      - 0.08108776135713698
      - 0.08923757258524104
      - 0.09676548542270347
      - 0.08787032075120184
      - 0.08749381688219081
      - 0.08635210413216377
      - 0.10037203346667838
      - 0.10646054150061154
      - 0.10377839155381566
      - 0.1037968653643908
      - 0.10487707237727319
      - 0.10498547982380196
      - 0.1068721648159984
  model_2:
    train:
      accuracy: []
      loss: []
      mcc: []
    validate:
      accuracy:
      - 0.5452593889368579
      - 0.5472952098796727
      - 0.5590902969763702
      - 0.5576089797922987
      - 0.5606745934299227
      - 0.5440474021498903
      - 0.5620370883799777
      - 0.564619491599268
      - 0.5619895594863711
      - 0.5673999318752525
      - 0.5678356133999795
      - 0.5674791466979301
      - 0.5617202290892672
      - 0.5689208564706628
      loss:
      - 0.7187076844081708
      - 0.696054884523732
      - 0.6903770027477254
      - 0.684633994742912
      - 0.6818154784042465
      - 0.687230062515998
      - 0.683262527991845
      - 0.6794731542519418
      - 0.6835486732247368
      - 0.6803100315919333
      - 0.6786320245642081
      - 0.6794076725780487
      - 0.6805335649508102
      - 0.6793636224249073
      mcc:
      - 0.05035113279553488
      - 0.07523057068105067
      - 0.08202458449450116
      - 0.09441356284206642
      - 0.09526997623332578
      - 0.09982123685201207
      - 0.08673243483768643
      - 0.09965398075344026
      - 0.08664287043916265
      - 0.10158144153574247
      - 0.11200199160114317
      - 0.10255355967194824
      - 0.11477675629032351
      - 0.10609228050459743
  model_3:
    train:
      accuracy: []
      loss: []
      mcc: []
    validate:
      accuracy:
      - 0.5297966555501865
      - 0.5479447714256291
      - 0.5454811904403551
      - 0.5596289577705781
      - 0.5574584716292112
      - 0.5597715444513978
      - 0.5637718929966176
      - 0.5631144099683932
      - 0.56588692876211
      - 0.5620846172735843
      - 0.5666869984711539
      - 0.5644610619539128
      - 0.5666632340243506
      - 0.5652373672161535
      - 0.5615459564793764
      - 0.5612132542241304
      - 0.5674791466979301
      loss:
      - 0.7151939829936266
      - 0.6997341715004025
      - 0.6921489575226518
      - 0.6859010610777881
      - 0.6919042094368053
      - 0.6820625274690484
      - 0.6809112884084244
      - 0.68402796154186
      - 0.679426214175585
      - 0.6878805054891466
      - 0.6804005642308145
      - 0.6793446261400483
      - 0.6793384829611463
      - 0.6789648696847606
      - 0.6807103189452323
      - 0.6810084879849256
      - 0.6790844630717812
      mcc:
      - 0.055996897379340445
      - 0.07257555474632901
      - 0.0867105771577055
      - 0.08970648812303136
      - 0.07608049710586849
      - 0.09597815251563988
      - 0.09579684971105507
      - 0.09234647047609003
      - 0.1051651031578809
      - 0.09003438667626483
      - 0.10309737096009292
      - 0.11033536956770797
      - 0.1092062579776341
      - 0.10891377481665783
      - 0.11344793879897035
      - 0.1133384754220807
      - 0.10885267084057682
  model_4:
    train:
      accuracy: []
      loss: []
      mcc: []
    validate:
      accuracy:
      - 0.5474457180427602
      - 0.5522778222260949
      - 0.5543215646511775
      - 0.5545750520837459
      - 0.5620450098622454
      - 0.5597873874159333
      - 0.5641600456277379
      - 0.5666315480952796
      - 0.5620450098622454
      - 0.5651739953580114
      - 0.5589239458487473
      - 0.5676375763432854
      - 0.5660295154429297
      - 0.5531729497223521
      - 0.5675900474496788
      loss:
      - 0.7218365403100232
      - 0.6948169621901022
      - 0.6872361427606031
      - 0.7005386332538486
      - 0.6826837387363458
      - 0.6812012744748402
      - 0.6823914560419028
      - 0.6797143326183087
      - 0.6800904144082224
      - 0.6790956429968539
      - 0.6807641789971894
      - 0.6783360418873252
      - 0.6784241887062795
      - 0.6827807954055186
      - 0.6824830658114434
      mcc:
      - 0.052628235622120545
      - 0.07135977276507509
      - 0.08040054537837914
      - 0.06665765077560036
      - 0.09368549030059364
      - 0.09918564321656109
      - 0.09407250825294723
      - 0.1050966501015454
      - 0.10719664236600347
      - 0.10546349795304628
      - 0.10884012494987667
      - 0.10639953344428285
      - 0.11251428739057559
      - 0.10764452450994916
      - 0.10367467591994188
sample_stats:
  model_0:
    train:
      negative: 0
      positive: 0
      total: 0
    validate:
      negative: 0
      positive: 0
      total: 0
  model_1:
    train:
      negative: 0
      positive: 0
      total: 0
    validate:
      negative: 0
      positive: 0
      total: 0
  model_2:
    train:
      negative: 0
      positive: 0
      total: 0
    validate:
      negative: 0
      positive: 0
      total: 0
  model_3:
    train:
      negative: 0
      positive: 0
      total: 0
    validate:
      negative: 0
      positive: 0
      total: 0
  model_4:
    train:
      negative: 0
      positive: 0
      total: 0
    validate:
      negative: 0
      positive: 0
      total: 0
train:
  MCC: {}
  accy: {}
  diff: {}
  epoch: {}
  loss: {}
validation:
  MCC:
    0: 0.106
    1: 0.104
    2: 0.112
    3: 0.109
    4: 0.106
    Mean: 0.107
  accy:
    0: 0.563
    1: 0.566
    2: 0.568
    3: 0.565
    4: 0.568
    Mean: 0.566
  diff:
    0: 0.268
    1: 0.466
    2: 0.349
    3: 0.319
    4: 0.487
    Mean: 0.378
  epoch:
    0: 11.0
    1: 12.0
    2: 10.0
    3: 13.0
    4: 11.0
    Mean: 11.4
  loss:
    0: 0.679
    1: 0.679
    2: 0.679
    3: 0.679
    4: 0.678
    Mean: 0.679
